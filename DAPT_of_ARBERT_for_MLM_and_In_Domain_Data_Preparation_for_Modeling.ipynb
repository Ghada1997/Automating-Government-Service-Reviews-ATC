{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFTO9GPXjE1E"
      },
      "source": [
        "# **Installing the required Packages**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dkKPOowFi4Ez"
      },
      "outputs": [],
      "source": [
        "!pip install transformers[torch]\n",
        "!pip install accelerate -U\n",
        "!pip install datasets\n",
        "!pip install transformers\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sm73M_mLjWZX"
      },
      "source": [
        "# **Importing the required Libraries and tool**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kt2YujmmjYyg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import logging\n",
        "import transformers\n",
        "\n",
        "\n",
        "\n",
        "from transformers import EarlyStoppingCallback, AutoTokenizer, Trainer, TrainingArguments, DataCollatorWithPadding, DataCollatorForLanguageModeling, AutoModelForMaskedLM\n",
        "\n",
        "from datasets import Dataset\n",
        "from google.colab import drive\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQYtVIycjcUn"
      },
      "source": [
        "## **Data Preparation for Modeling**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CfiCfZM6jfA8"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Mounting Google Drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "\n",
        "# Defining the data file path in Google Drive. Replace it with the actual file path\n",
        "drive_file_path = \"/content/drive/MyDrive/######\"\n",
        "\n",
        "# Reading the CSV file into a DataFrame\n",
        "preprocessed_df = pd.read_csv(drive_file_path)\n",
        "\n",
        "# Displaying the DataFrame\n",
        "preprocessed_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x15GOnd_kWmo"
      },
      "source": [
        "***Utilizing GPU Capabilities***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YFTx0Q5XkUJW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# Checking if CUDA is available\n",
        "if torch.cuda.is_available():\n",
        "    print(\"CUDA is available. Running on GPU.\")\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    print(\"CUDA is not available. Running on CPU.\")\n",
        "    device = torch.device(\"cpu\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDtan5KGoMfE"
      },
      "source": [
        "## **Preparing the data to apply the further pretraining for ARBERT**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fc1Gd-5tr72J"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Renaming Columns\n",
        "preprocessed_df.rename(columns={'Sector': 'sector', 'Keyword': 'keyword', 'Processed_Content':'text'}, inplace=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64ElVPdWqNaR"
      },
      "source": [
        "***Preparing Training and Validation Dataset***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YvpzR5cuhEHz"
      },
      "outputs": [],
      "source": [
        "# Creating a combined column for stratification to be used for creating the validation dataset\n",
        "preprocessed_df['stratify_col'] = preprocessed_df['sector'] + '_' + preprocessed_df['keyword']\n",
        "\n",
        "# Adopting ARBERT tokenizer\n",
        "# Loading the model\n",
        "ARBERT_model = AutoModelForMaskedLM.from_pretrained(\"UBC-NLP/ARBERT\")\n",
        "ARBERT_tokenizer = AutoTokenizer.from_pretrained(\"UBC-NLP/ARBERT\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "***Some EDA to understand the Token (Article) length distribution in the data which will affect the ARBERT max_length property***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizing the Distribution of Article Lengths to decide on the max_length\n",
        "\n",
        "# Step 1: Calculate Article Lengths\n",
        "article_lengths = []\n",
        "\n",
        "# Tokenize and calculate length for each article\n",
        "for review_text in preprocessed_df['text']:\n",
        "    # Tokenize the article\n",
        "    tokens = ARBERT_tokenizer.tokenize(review_text)\n",
        "    # Calculate the length (number of tokens) of the article\n",
        "    length = len(tokens)\n",
        "    article_lengths.append(length)\n",
        "\n",
        "\n",
        "# Step 2: Summary Statistics\n",
        "mean_length = sum(article_lengths) / len(article_lengths)\n",
        "median_length = sorted(article_lengths)[len(article_lengths) // 2]\n",
        "min_length = min(article_lengths)\n",
        "max_length = max(article_lengths)\n",
        "\n",
        "# Step 3: Visualize the Distribution\n",
        "plt.figure(figsize=(9, 5))\n",
        "\n",
        "ax = sns.histplot(article_lengths, bins=50, alpha=0.6, color='royalblue', edgecolor='black', kde=True)\n",
        "ax.axvline(mean_length, color='k', linestyle='--') # mean\n",
        "ax.axvline(median_length, color='b', linestyle='--', ) # median\n",
        "\n",
        "plt.title('Distribution of Article Lengths', fontsize=20, fontweight='bold')\n",
        "plt.xlabel('Length of Article', fontsize=18)\n",
        "plt.ylabel('Frequency', fontsize=18)\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "print(\"Mean Article Length:\", mean_length)\n",
        "print(\"Median Article Length:\", median_length)\n",
        "print(\"Minimum Article Length:\", min_length)\n",
        "print(\"Maximum Article Length:\", max_length)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def tokenize_function(examples): # Setting the max_length to 400 based on the previous Article Length Distribution\n",
        "    \n",
        "    return ARBERT_tokenizer.batch_encode_plus(examples['text'],\n",
        "                                              return_attention_mask=True,\n",
        "                                              padding='max_length',  # Pad to the maximum sequence length\n",
        "                                              truncation=True,  # Truncate sequences longer than the maximum sequence length\n",
        "                                              return_tensors='pt',  # Return PyTorch tensors\n",
        "                                              max_length=400,  # Adjust max_length as needed\n",
        "                                              add_special_tokens=True, # Add special tokens\n",
        "                                              return_special_tokens_mask=True)\n",
        "\n",
        "\n",
        "def prepare_data(data, test_size, stratify_column ):\n",
        "  # Stratified split ensuring each category is proportionally represented\n",
        "  # The test size here was set to 0.1 to split the data into 90% train and 100% for validation\n",
        "  train_df_mlm, eval_df_mlm = train_test_split(data, test_size=test_size, stratify=stratify_column, random_state=1)\n",
        "\n",
        "  # Dropping the stratify column\n",
        "  train_df_mlm = train_df_mlm.drop(columns=['stratify_column'])\n",
        "  eval_df_mlm = eval_df_mlm.drop(columns=['stratify_column'])\n",
        "\n",
        "  # Converting the split DataFrames to Dataset objects\n",
        "  train_dataset_mlm = Dataset.from_pandas(train_df_mlm)\n",
        "  eval_dataset_mlm = Dataset.from_pandas(eval_df_mlm)\n",
        "\n",
        "\n",
        "  # Tokenize the train and val datasets\n",
        "  tokenized_train_dataset_final_mlm = train_dataset_mlm.map(tokenize_function, batched=True, remove_columns=['']) # Remove extra columns as needed\n",
        "  tokenized_eval_dataset_mlm = eval_dataset_mlm.map(tokenize_function, batched=True, remove_columns=['']) # Remove extra columns as needed\n",
        "\n",
        "  # Remove the unnecessary column '__index_level_0__' if present\n",
        "  if '__index_level_0__' in tokenized_train_dataset_final_mlm.column_names:\n",
        "     tokenized_train_dataset_final_mlm = tokenized_train_dataset_final_mlm.remove_columns(['__index_level_0__'])\n",
        "  if '__index_level_0__' in tokenized_eval_dataset_mlm.column_names:\n",
        "     tokenized_eval_dataset_mlm = tokenized_eval_dataset_mlm.remove_columns(['__index_level_0__'])\n",
        "\n",
        "  return tokenized_train_dataset_final_mlm, tokenized_eval_dataset_mlm\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HdaYwZMFt5Yl"
      },
      "outputs": [],
      "source": [
        "# Defining data collators for MLM\n",
        "data_collator_mlm = DataCollatorForLanguageModeling(tokenizer=ARBERT_tokenizer, mlm=True, mlm_probability=0.15,  return_tensors='pt')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMjCwXSgt_81"
      },
      "source": [
        "# **Modeling: Further Pretraining ARBERT for MLM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PC-WnvM3uAFw"
      },
      "outputs": [],
      "source": [
        "# Initializing logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Custom logging callback\n",
        "class CustomCallback(transformers.TrainerCallback):\n",
        "    def on_step_end(self, args, state, control, **kwargs):\n",
        "        # Custom logging every 100 steps\n",
        "        if state.global_step % 100 == 0:\n",
        "            logger.info(f\"Step {state.global_step}: Continuing training...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OdTaSsO2kzCa"
      },
      "outputs": [],
      "source": [
        "# Specify output directory in Google Drive for checkpoints\n",
        "output_dir_checkpoints = \"/content/drive/MyDrive/#########\"\n",
        "\n",
        "final_output_dir_checkpoints_DAPT = \"/content/drive/MyDrive/#########\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6AjpdHjkuXS8"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainerCallback\n",
        "class EarlyStoppingCallback(TrainerCallback):\n",
        "    def __init__(self, early_stopping_patience=3):\n",
        "        self.early_stopping_patience = early_stopping_patience\n",
        "        self.best_metric = None\n",
        "        self.patience_counter = 0\n",
        "\n",
        "    def on_evaluate(self, args, state, control, metrics=None, **kwargs):\n",
        "        if state.is_world_process_zero:\n",
        "            current_metric = metrics[\"eval_loss\"]\n",
        "            if self.best_metric is None or current_metric > self.best_metric:\n",
        "                self.best_metric = current_metric\n",
        "                self.patience_counter = 0\n",
        "            else:\n",
        "                self.patience_counter += 1\n",
        "\n",
        "            if self.patience_counter >= self.early_stopping_patience:\n",
        "                control.should_training_stop = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRaEw16hurBP"
      },
      "source": [
        "***Defining Training Arguments***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PwyijJaBfnTh"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "# Function to compute Perplexity from Loss\n",
        "def compute_metrics(eval_preds):\n",
        "    loss = eval_preds[\"eval_loss\"]\n",
        "    perplexity = math.exp(loss)\n",
        "    return {\"perplexity\": perplexity}\n",
        "\n",
        "# Hyperparameter settings and seed can be decided as needed\n",
        "\n",
        "def training_model_with_validation(tokenized_train_dataset_mlm, tokenized_eval_dataset_mlm, learning_rate, num_epochs, batch_size, weight_decay, warmup_proportion, seed=1):\n",
        "  # Calculate total steps and warmup steps\n",
        "  total_steps = len(tokenized_train_dataset_mlm) // batch_size * num_epochs\n",
        "  warmup_steps = int(total_steps * warmup_proportion)\n",
        "\n",
        "  training_args = TrainingArguments(\n",
        "    output_dir = output_dir_checkpoints,\n",
        "    overwrite_output_dir=True,\n",
        "    resume_from_checkpoint=False,\n",
        "    num_train_epochs= num_epochs,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    learning_rate=learning_rate,\n",
        "    weight_decay=weight_decay,\n",
        "    warmup_steps=warmup_steps,\n",
        "    logging_steps=1000,\n",
        "    logging_dir='./logs',\n",
        "    save_strategy='steps',        # Save based on steps\n",
        "    save_steps=1000,\n",
        "    save_total_limit=2,\n",
        "    gradient_accumulation_steps=2,\n",
        "    fp16=True,  # Enable mixed precision training\n",
        "    seed=seed,\n",
        "    lr_scheduler_type=\"linear\",  # Use linear learning rate decay\n",
        "    eval_strategy=\"steps\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"perplexity\",\n",
        "    dropout=0.1\n",
        "\n",
        "\n",
        "  )\n",
        "\n",
        "  # Creating Trainer object for MLM and start training\n",
        "  final_trainer_mlm  = Trainer(\n",
        "    model=ARBERT_model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator_mlm,\n",
        "    train_dataset=tokenized_train_dataset_mlm,\n",
        "    eval_dataset=tokenized_eval_dataset_mlm,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
        "  )\n",
        "\n",
        "  # Start pretraining for MLM\n",
        "  final_trainer_mlm.train()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeklJBolTkz7"
      },
      "source": [
        "### **Plotting Training-Validation Losses**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XIAPiQi7Tjt3"
      },
      "outputs": [],
      "source": [
        "# loss data for the adopted training data\n",
        "\n",
        "training_losses = []  # Add the logged training loss values here\n",
        "validation_losses = []  # Add the validation loss values from logs or callbacks\n",
        "steps = [] # Add the number of training steps\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(steps, training_losses, label='Training Loss')\n",
        "plt.plot(steps, validation_losses, label='Validation Loss')\n",
        "plt.xlabel('Steps')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Training and Validation Loss over Steps')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9ecv-C6LrRR"
      },
      "source": [
        "## **Plotting Perplexity**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ATboM8fISeCG"
      },
      "outputs": [],
      "source": [
        "perplexity = [] # Add the perplexity values per steps\n",
        "steps = []  # Add the number of training steps\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(steps, perplexity, label='Perplexity')\n",
        "plt.xlabel('Steps')\n",
        "plt.ylabel('Perplexity')\n",
        "plt.legend()\n",
        "plt.title('Perplexity over Steps')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNu_ZRInU0aX"
      },
      "source": [
        "### **Retrain and Save the Model and Tokenizer to Google Drive**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KdfnP1QGuhPA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def training_model_without_validation(full_dataset_mlm, learning_rate, num_epochs, batch_size, weight_decay, warmup_proportion, seed = 1):\n",
        "  # Calculate total steps and warmup steps\n",
        "  total_steps = len(full_dataset_mlm) // batch_size * num_epochs\n",
        "  warmup_steps = int(total_steps * warmup_proportion)\n",
        "\n",
        "  training_args = TrainingArguments(\n",
        "    output_dir = final_output_dir_checkpoints_DAPT,\n",
        "    overwrite_output_dir=True,\n",
        "    resume_from_checkpoint=False,\n",
        "    num_train_epochs= num_epochs,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    learning_rate=learning_rate,\n",
        "    weight_decay=weight_decay,\n",
        "    warmup_steps=warmup_steps,\n",
        "    logging_steps=1000,\n",
        "    logging_dir='./logs',\n",
        "    save_strategy='steps',        # Save based on steps\n",
        "    save_steps=1000,\n",
        "    save_total_limit=2,\n",
        "    gradient_accumulation_steps=2,\n",
        "    fp16=True,  # Enable mixed precision training\n",
        "    evaluation_strategy=\"no\",  # Disable evaluation\n",
        "    seed=seed,\n",
        "    lr_scheduler_type=\"linear\",  # Use linear learning rate decay\n",
        "    dropout=0.1\n",
        "\n",
        "\n",
        "  )\n",
        "\n",
        "  # Creating Trainer object for MLM and start training\n",
        "  final_trainer_mlm  = Trainer(\n",
        "    model=ARBERT_model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator_mlm,\n",
        "    train_dataset=full_dataset_mlm,\n",
        "    eval_dataset=None,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
        "  )\n",
        "\n",
        "  # Start pretraining for MLM\n",
        "  final_trainer_mlm.train()\n",
        "\n",
        "  # Define the save path to Google Drive\n",
        "  model_save_path = \"/content/drive/MyDrive/#####\"\n",
        "  os.makedirs(model_save_path, exist_ok=True)\n",
        "  # Save the best model and tokenizer to Google Drive\n",
        "  final_trainer_mlm.model.save_pretrained(model_save_path)\n",
        "  ARBERT_tokenizer.save_pretrained(model_save_path)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
